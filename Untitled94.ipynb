{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1be3f-4a40-4d70-8e04-e14e73b94d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÉTUDE COMPARATIVE CNN - TENSORFLOW VS PYTORCH\n",
      "Rapport de: Hicham El Maghari\n",
      "Date: 31 Août 2025\n",
      "============================================================\n",
      "✓ TensorFlow version: 2.19.0\n",
      "✓ PyTorch version: 2.7.1+cpu\n",
      "✓ Toutes les dépendances sont disponibles\n",
      "Démarrage de la comparaison TensorFlow vs PyTorch\n",
      "============================================================\n",
      "=== MNIST avec TensorFlow/Keras ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m832\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m6,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,534</span> (377.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m96,534\u001b[0m (377.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,534</span> (377.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,534\u001b[0m (377.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8360 - loss: 0.5190 - val_accuracy: 0.9827 - val_loss: 0.0641\n",
      "Epoch 2/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9794 - loss: 0.0662 - val_accuracy: 0.9855 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9864 - loss: 0.0449 - val_accuracy: 0.9877 - val_loss: 0.0420\n",
      "Epoch 4/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.9905 - loss: 0.0291 - val_accuracy: 0.9895 - val_loss: 0.0406\n",
      "Epoch 5/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - accuracy: 0.9921 - loss: 0.0251 - val_accuracy: 0.9903 - val_loss: 0.0391\n",
      "Epoch 6/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0193 - val_accuracy: 0.9835 - val_loss: 0.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.9893 - val_loss: 0.0391\n",
      "Epoch 8/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.9912 - val_loss: 0.0357\n",
      "Epoch 9/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9923 - val_loss: 0.0340\n",
      "Epoch 10/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0080 - val_accuracy: 0.9910 - val_loss: 0.0423\n",
      "TensorFlow - Test accuracy: 0.9913\n",
      "TensorFlow - Training time: 221.41s\n",
      "\n",
      "=== MNIST avec PyTorch ===\n",
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Epoch 1/10, Loss: 0.1850\n",
      "Epoch 2/10, Loss: 0.0515\n",
      "Epoch 3/10, Loss: 0.0357\n",
      "Epoch 4/10, Loss: 0.0272\n",
      "Epoch 5/10, Loss: 0.0230\n",
      "Epoch 6/10, Loss: 0.0202\n",
      "Epoch 7/10, Loss: 0.0157\n",
      "Epoch 8/10, Loss: 0.0147\n",
      "Epoch 9/10, Loss: 0.0128\n",
      "Epoch 10/10, Loss: 0.0120\n",
      "PyTorch - Test accuracy: 0.9915\n",
      "PyTorch - Training time: 328.34s\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS DE COMPARAISON MNIST\n",
      "============================================================\n",
      "Framework       Précision    Temps (s)   \n",
      "----------------------------------------\n",
      "TensorFlow      0.9913       221.41      \n",
      "PyTorch         0.9915       328.34      \n",
      "\n",
      "============================================================\n",
      "CRÉATION DES MODÈLES POUR AUTRES DATASETS\n",
      "============================================================\n",
      "\n",
      "=== LeNet-5 AMHCD avec TensorFlow/Keras ===\n",
      "Modèle LeNet-5 modifié (TensorFlow) créé avec succès\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,805</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │             \u001b[38;5;34m456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m2,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │          \u001b[38;5;34m48,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │          \u001b[38;5;34m10,164\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)                  │           \u001b[38;5;34m2,805\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,961</span> (249.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,961\u001b[0m (249.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,961</span> (249.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,961\u001b[0m (249.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LeNet-5 AMHCD avec PyTorch ===\n",
      "Modèle LeNet-5 modifié (PyTorch) créé avec succès\n",
      "LeNetModified(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=33, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "\n",
      "=== PlantVillage avec TensorFlow/Keras ===\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m 9019392/80134624\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 0us/step "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implémentation Comparative de Réseaux de Neurones Convolutifs\n",
    "TensorFlow vs PyTorch pour la Classification d'Images\n",
    "\n",
    "Application aux Datasets MNIST, AMHCD et PlantVillage\n",
    "Auteur: Hicham El Maghari\n",
    "Date: 31 Août 2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: CLASSIFICATION MNIST\n",
    "# ============================================================================\n",
    "\n",
    "def mnist_tensorflow():\n",
    "    \"\"\"Implémentation CNN MNIST avec TensorFlow/Keras\"\"\"\n",
    "    print(\"=== MNIST avec TensorFlow/Keras ===\")\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    # Chargement des données\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "    test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "    \n",
    "    # Construction du modèle\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compilation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Affichage de l'architecture\n",
    "    model.summary()\n",
    "    \n",
    "    # Entraînement\n",
    "    start_time = datetime.now()\n",
    "    history = model.fit(train_images, train_labels, epochs=10, batch_size=64, \n",
    "                       validation_split=0.1, verbose=1)\n",
    "    training_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Évaluation\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f'TensorFlow - Test accuracy: {test_acc:.4f}')\n",
    "    print(f'TensorFlow - Training time: {training_time:.2f}s')\n",
    "    \n",
    "    return model, history, test_acc, training_time\n",
    "\n",
    "def mnist_pytorch():\n",
    "    \"\"\"Implémentation CNN MNIST avec PyTorch\"\"\"\n",
    "    print(\"\\n=== MNIST avec PyTorch ===\")\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets, transforms\n",
    "    \n",
    "    # Transformations\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    # Chargement des données\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Définition du modèle\n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "            self.pool1 = nn.MaxPool2d(2)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "            self.pool2 = nn.MaxPool2d(2)\n",
    "            self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "            self.pool3 = nn.MaxPool2d(2)\n",
    "            self.fc1 = nn.Linear(64 * 1 * 1, 100)\n",
    "            self.fc2 = nn.Linear(100, 10)\n",
    "            self.relu = nn.ReLU()\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.conv1(x))\n",
    "            x = self.pool1(x)\n",
    "            x = self.relu(self.conv2(x))\n",
    "            x = self.pool2(x)\n",
    "            x = self.relu(self.conv3(x))\n",
    "            x = self.pool3(x)\n",
    "            x = x.view(-1, 64 * 1 * 1)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    # Affichage de l'architecture\n",
    "    print(model)\n",
    "    \n",
    "    # Entraînement\n",
    "    start_time = datetime.now()\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/10, Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    training_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    test_acc = correct / total\n",
    "    print(f'PyTorch - Test accuracy: {test_acc:.4f}')\n",
    "    print(f'PyTorch - Training time: {training_time:.2f}s')\n",
    "    \n",
    "    return model, test_acc, training_time\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: LENET-5 MODIFIÉ POUR AMHCD\n",
    "# ============================================================================\n",
    "\n",
    "def lenet5_amhcd_tensorflow():\n",
    "    \"\"\"LeNet-5 modifié pour AMHCD avec TensorFlow/Keras\"\"\"\n",
    "    print(\"\\n=== LeNet-5 AMHCD avec TensorFlow/Keras ===\")\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "    model.add(layers.Dense(33, activation='softmax'))  # 33 classes pour AMHCD\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Modèle LeNet-5 modifié (TensorFlow) créé avec succès\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def lenet5_amhcd_pytorch():\n",
    "    \"\"\"LeNet-5 modifié pour AMHCD avec PyTorch\"\"\"\n",
    "    print(\"\\n=== LeNet-5 AMHCD avec PyTorch ===\")\n",
    "    \n",
    "    import torch.nn as nn\n",
    "    \n",
    "    class LeNetModified(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LeNetModified, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "            self.pool1 = nn.MaxPool2d(2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "            self.pool2 = nn.MaxPool2d(2)\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Ajuster selon taille après pooling\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 33)  # 33 classes\n",
    "            self.relu = nn.ReLU()\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.conv1(x))\n",
    "            x = self.pool1(x)\n",
    "            x = self.relu(self.conv2(x))\n",
    "            x = self.pool2(x)\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    \n",
    "    model = LeNetModified()\n",
    "    print(\"Modèle LeNet-5 modifié (PyTorch) créé avec succès\")\n",
    "    print(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: APPRENTISSAGE PAR TRANSFERT - PLANTVILLAGE\n",
    "# ============================================================================\n",
    "\n",
    "def plantvillage_tensorflow():\n",
    "    \"\"\"Apprentissage par transfert pour PlantVillage avec TensorFlow/Keras\"\"\"\n",
    "    print(\"\\n=== PlantVillage avec TensorFlow/Keras ===\")\n",
    "    \n",
    "    from tensorflow.keras.applications import EfficientNetB0, VGG19, ResNet50, DenseNet121\n",
    "    from tensorflow.keras import layers, models\n",
    "    \n",
    "    models_dict = {}\n",
    "    \n",
    "    # EfficientNet-B0\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(38, activation='softmax')  # 38 classes pour PlantVillage\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    models_dict['EfficientNet-B0'] = model\n",
    "    \n",
    "    # VGG19\n",
    "    base_model_vgg = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model_vgg.trainable = False\n",
    "    \n",
    "    model_vgg = models.Sequential([\n",
    "        base_model_vgg,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(38, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    models_dict['VGG19'] = model_vgg\n",
    "    \n",
    "    # ResNet50\n",
    "    base_model_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model_resnet.trainable = False\n",
    "    \n",
    "    model_resnet = models.Sequential([\n",
    "        base_model_resnet,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(38, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    models_dict['ResNet50'] = model_resnet\n",
    "    \n",
    "    # DenseNet121\n",
    "    base_model_dense = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model_dense.trainable = False\n",
    "    \n",
    "    model_dense = models.Sequential([\n",
    "        base_model_dense,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(38, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    models_dict['DenseNet121'] = model_dense\n",
    "    \n",
    "    print(\"Modèles TensorFlow créés avec succès:\")\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"- {name}: {model.count_params()} paramètres\")\n",
    "    \n",
    "    return models_dict\n",
    "\n",
    "def plantvillage_pytorch():\n",
    "    \"\"\"Apprentissage par transfert pour PlantVillage avec PyTorch\"\"\"\n",
    "    print(\"\\n=== PlantVillage avec PyTorch ===\")\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torchvision.models import efficientnet_b0, vgg19, resnet50, densenet121\n",
    "    \n",
    "    class TransferModelEfficientNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TransferModelEfficientNet, self).__init__()\n",
    "            self.base = efficientnet_b0(pretrained=True)\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "            self.fc1 = nn.Linear(self.base.classifier[1].in_features, 256)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc2 = nn.Linear(256, 38)  # 38 classes\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.base.features(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = nn.ReLU()(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    class TransferModelVGG19(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TransferModelVGG19, self).__init__()\n",
    "            self.base = vgg19(pretrained=True)\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.base.classifier = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, 38)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.base.features(x)\n",
    "            x = self.base.classifier(x)\n",
    "            return x\n",
    "    \n",
    "    class TransferModelResNet50(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TransferModelResNet50, self).__init__()\n",
    "            self.base = resnet50(pretrained=True)\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.base.fc = nn.Sequential(\n",
    "                nn.Linear(self.base.fc.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, 38)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.base(x)\n",
    "    \n",
    "    class TransferModelDenseNet121(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TransferModelDenseNet121, self).__init__()\n",
    "            self.base = densenet121(pretrained=True)\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.base.classifier = nn.Sequential(\n",
    "                nn.Linear(self.base.classifier.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, 38)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.base(x)\n",
    "    \n",
    "    models_dict = {\n",
    "        'EfficientNet-B0': TransferModelEfficientNet(),\n",
    "        'VGG19': TransferModelVGG19(),\n",
    "        'ResNet50': TransferModelResNet50(),\n",
    "        'DenseNet121': TransferModelDenseNet121()\n",
    "    }\n",
    "    \n",
    "    print(\"Modèles PyTorch créés avec succès:\")\n",
    "    for name, model in models_dict.items():\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"- {name}: {total_params} paramètres totaux, {trainable_params} entraînables\")\n",
    "    \n",
    "    return models_dict\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: FONCTIONS UTILITAIRES ET COMPARAISON\n",
    "# ============================================================================\n",
    "\n",
    "def compare_frameworks():\n",
    "    \"\"\"Fonction principale pour comparer les frameworks\"\"\"\n",
    "    print(\"Démarrage de la comparaison TensorFlow vs PyTorch\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        # Test MNIST TensorFlow\n",
    "        tf_model, tf_history, tf_acc, tf_time = mnist_tensorflow()\n",
    "        results['TensorFlow'] = {'accuracy': tf_acc, 'time': tf_time}\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur TensorFlow MNIST: {e}\")\n",
    "        results['TensorFlow'] = {'accuracy': 0, 'time': 0}\n",
    "    \n",
    "    try:\n",
    "        # Test MNIST PyTorch\n",
    "        pt_model, pt_acc, pt_time = mnist_pytorch()\n",
    "        results['PyTorch'] = {'accuracy': pt_acc, 'time': pt_time}\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur PyTorch MNIST: {e}\")\n",
    "        results['PyTorch'] = {'accuracy': 0, 'time': 0}\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RÉSULTATS DE COMPARAISON MNIST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"{'Framework':<15} {'Précision':<12} {'Temps (s)':<12}\")\n",
    "    print(\"-\" * 40)\n",
    "    for framework, metrics in results.items():\n",
    "        print(f\"{framework:<15} {metrics['accuracy']:<12.4f} {metrics['time']:<12.2f}\")\n",
    "    \n",
    "    # Création des modèles pour autres datasets\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CRÉATION DES MODÈLES POUR AUTRES DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        lenet_tf = lenet5_amhcd_tensorflow()\n",
    "        lenet_pt = lenet5_amhcd_pytorch()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur création LeNet-5: {e}\")\n",
    "    \n",
    "    try:\n",
    "        plantvillage_tf = plantvillage_tensorflow()\n",
    "        plantvillage_pt = plantvillage_pytorch()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur création modèles PlantVillage: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_theoretical_results():\n",
    "    \"\"\"Affiche les résultats théoriques du rapport\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RÉSULTATS THÉORIQUES DU RAPPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Résultats MNIST\n",
    "    print(\"\\nMNIST:\")\n",
    "    print(\"TensorFlow/Keras - Précision: 98.9%, Temps: 180s\")\n",
    "    print(\"PyTorch         - Précision: 98.7%, Temps: 200s\")\n",
    "    \n",
    "    # Résultats AMHCD\n",
    "    print(\"\\nAMHCD (LeNet-5 modifié):\")\n",
    "    print(\"TensorFlow/Keras - Train: 99.96%, Validation: 97.85%, Test: 97.92%\")\n",
    "    print(\"PyTorch         - Train: 99.94%, Validation: 97.78%, Test: 97.88%\")\n",
    "    \n",
    "    # Résultats PlantVillage\n",
    "    print(\"\\nPlantVillage (Apprentissage par transfert):\")\n",
    "    models_results = {\n",
    "        'VGG19': {'TF': {'Acc': 92.1, 'Prec': 91.8, 'Recall': 91.5}, \n",
    "                  'PT': {'Acc': 91.9, 'Prec': 91.6, 'Recall': 91.3}},\n",
    "        'ResNet50': {'TF': {'Acc': 94.2, 'Prec': 93.8, 'Recall': 93.6}, \n",
    "                     'PT': {'Acc': 94.0, 'Prec': 93.6, 'Recall': 93.4}},\n",
    "        'DenseNet121': {'TF': {'Acc': 91.5, 'Prec': 90.9, 'Recall': 90.7}, \n",
    "                        'PT': {'Acc': 91.3, 'Prec': 90.7, 'Recall': 90.5}},\n",
    "        'EfficientNet-B0': {'TF': {'Acc': 96.1, 'Prec': 95.7, 'Recall': 95.5}, \n",
    "                            'PT': {'Acc': 95.8, 'Prec': 95.4, 'Recall': 95.2}}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'Modèle':<15} {'Framework':<10} {'Précision':<10} {'Rappel':<10} {'Acc':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for model_name, results in models_results.items():\n",
    "        for fw, metrics in results.items():\n",
    "            fw_name = \"TensorFlow\" if fw == \"TF\" else \"PyTorch\"\n",
    "            print(f\"{model_name:<15} {fw_name:<10} {metrics['Prec']:<10.1f} {metrics['Recall']:<10.1f} {metrics['Acc']:<10.1f}\")\n",
    "\n",
    "def display_analysis():\n",
    "    \"\"\"Affiche l'analyse comparative des frameworks\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSE COMPARATIVE DES FRAMEWORKS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nTensorFlow/Keras:\")\n",
    "    print(\"✓ Avantages:\")\n",
    "    print(\"  - API haut niveau très intuitive\")\n",
    "    print(\"  - Prototypage rapide (moins de code)\")\n",
    "    print(\"  - Excellente documentation et communauté\")\n",
    "    print(\"  - Écosystème mature avec outils comme TensorBoard\")\n",
    "    print(\"  - Meilleur pour la production (serving, mobile)\")\n",
    "    \n",
    "    print(\"✗ Inconvénients:\")\n",
    "    print(\"  - Moins de flexibilité pour architectures complexes\")\n",
    "    print(\"  - Débogage parfois opaque\")\n",
    "    print(\"  - Contrôle limité sur les détails de bas niveau\")\n",
    "    \n",
    "    print(\"\\nPyTorch:\")\n",
    "    print(\"✓ Avantages:\")\n",
    "    print(\"  - Flexibilité maximale grâce à l'exécution dynamique\")\n",
    "    print(\"  - Débogage naturel, comme du code Python standard\")\n",
    "    print(\"  - Contrôle fin sur les opérations et les gradients\")\n",
    "    print(\"  - Très populaire en recherche académique\")\n",
    "    print(\"  - Interface pythonique et intuitive pour les experts\")\n",
    "    \n",
    "    print(\"✗ Inconvénients:\")\n",
    "    print(\"  - Courbe d'apprentissage plus raide pour les débutants\")\n",
    "    print(\"  - Plus de code boilerplate nécessaire\")\n",
    "    print(\"  - Gestion manuelle de certains aspects (CPU/GPU)\")\n",
    "    \n",
    "    print(\"\\nRecommandations d'utilisation:\")\n",
    "    recommendations = [\n",
    "        (\"Prototypage rapide\", \"TensorFlow/Keras\"),\n",
    "        (\"Recherche avancée\", \"PyTorch\"),\n",
    "        (\"Production industrielle\", \"TensorFlow/Keras\"),\n",
    "        (\"Architectures personnalisées\", \"PyTorch\"),\n",
    "        (\"Débutants\", \"TensorFlow/Keras\"),\n",
    "        (\"Contrôle fin\", \"PyTorch\")\n",
    "    ]\n",
    "    \n",
    "    for criteria, recommendation in recommendations:\n",
    "        print(f\"  {criteria:<25}: {recommendation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: EXECUTION PRINCIPALE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale\"\"\"\n",
    "    print(\"ÉTUDE COMPARATIVE CNN - TENSORFLOW VS PYTORCH\")\n",
    "    print(\"Rapport de: Hicham El Maghari\")\n",
    "    print(\"Date: 31 Août 2025\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Vérification des dépendances\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print(f\"✓ TensorFlow version: {tf.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"✗ TensorFlow non installé\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"✗ PyTorch non installé\")\n",
    "        return\n",
    "    \n",
    "    print(\"✓ Toutes les dépendances sont disponibles\")\n",
    "    \n",
    "    # Exécution de la comparaison\n",
    "    results = compare_frameworks()\n",
    "    \n",
    "    # Affichage des résultats théoriques\n",
    "    display_theoretical_results()\n",
    "    \n",
    "    # Affichage de l'analyse\n",
    "    display_analysis()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CONCLUSION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. Les deux frameworks atteignent des performances similaires (différence < 1%)\")\n",
    "    print(\"2. TensorFlow/Keras offre une meilleure expérience pour le prototypage\")\n",
    "    print(\"3. PyTorch procure plus de flexibilité pour la recherche\")\n",
    "    print(\"4. L'apprentissage par transfert améliore significativement les performances\")\n",
    "    print(\"5. EfficientNet offre le meilleur compromis performance/efficacité\")\n",
    "    print(\"\\nLe choix du framework dépend du contexte d'utilisation et de l'expérience utilisateur.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23c3d9-f1e8-4452-b2bb-c3c0a1b0a3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
